# -*- coding: utf-8 -*-
"""DBSCAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kmInFUZpKVrBLQnm2ckEfJC2YymrDUbV

#**DBSCAN(Density Based Spatial Clustering of Applications With Noise:**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df1=pd.read_csv("/content/Clustering_gmm.csv")

df2=pd.read_csv("/content/Mall_Customers.csv")

#shape of the dataset1
df1.shape

#shape of the dataset 2
df2.shape

#sample rows from df1
df1.head(5)

#sample rows from df2
df2.head(5)

#plotting the dataset1
plt.scatter(df1["Weight"],df1["Height"])
plt.xlabel("Weight")
plt.ylabel("Height")
plt.title("Cluster mall customers")
plt.show()

##plotting the dataset1
plt.scatter(df2["Annual Income (k$)"],df2["Spending Score (1-100)"])
plt.xlabel("Annual Income (k$)	")
plt.ylabel("Spending Score (1-100)")
plt.title("Cluster mall customers")
plt.show()

"""#Clustering using the K-Means Clustering on dataset1"""

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
wcss=[]
k=-1
max_score=float("-inf")
for i in range(2,15,1):
  km=KMeans(n_clusters=i,max_iter=300)
  labels=km.fit_predict(df1)
  wcss.append(km.inertia_)
  score=silhouette_score(df1,labels)
  if(score>max_score):
    max_score=score
    k=i

print("maximum silhoutte score: ",max_score)
print("better k value: ",k)

#using the plot between k and the wcss to find the optimal k value
plt.plot(range(2,15,1),wcss)
plt.xlabel("k values")
plt.ylabel("WCSS")
plt.title("Finding the best K value")
plt.show()

#using k=3 to cluster the data
km=KMeans(n_clusters=3,max_iter=300)
labels=km.fit_predict(df1)

df1["label"]=labels

#plotting the data and clusters
plt.scatter(df1.iloc[0:,0][df1["label"]==0],df1.iloc[0:,1][df1["label"]==0],color="green")
plt.scatter(df1.iloc[0:,0][df1["label"]==1],df1.iloc[0:,1][df1["label"]==1],color="blue")
plt.scatter(df1.iloc[0:,0][df1["label"]==2],df1.iloc[0:,1][df1["label"]==2])
plt.xlabel("Weight")
plt.ylabel("Height")
plt.title("clusterig using K Means Clustering")
plt.show()

"""#Clustering using the K-Means Clustering on dataset2"""

X=df2[["Annual Income (k$)","Spending Score (1-100)"]]

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
wcss=[]
k=-1
max_score=float("-inf")
for i in range(2,15,1):
  km=KMeans(n_clusters=i,max_iter=300)
  labels=km.fit_predict(X)
  wcss.append(km.inertia_)
  score=silhouette_score(X,labels)
  if(score>max_score):
    max_score=score
    k=i

print("maximum silhoutte score: ",max_score)
print("better k value: ",k)

#using the plot between k and the wcss to find the optimal k value
plt.plot(range(2,15,1),wcss)
plt.xlabel("k values")
plt.ylabel("WCSS")
plt.title("Finding the best K value")
plt.show()

#using k=2 to cluster the data
km=KMeans(n_clusters=2,max_iter=300)
labels=km.fit_predict(X)

X["label"]=labels

#plotting the data and clusters
plt.scatter(X.iloc[0:,0][X["label"]==0],X.iloc[0:,1][X["label"]==0],color="green")
plt.scatter(X.iloc[0:,0][X["label"]==1],X.iloc[0:,1][X["label"]==1],color="blue")
plt.scatter(X.iloc[0:,0][X["label"]==2],X.iloc[0:,1][X["label"]==2])
plt.xlabel("Weight")
plt.ylabel("Height")
plt.title("clusterig using K Means Clustering")
plt.show()

"""#Clustering using the Hierarchical Clustering on dataset1"""

df1[["Weight","Height"]]

#drawing the dendrogram
from scipy.cluster.hierarchy import linkage,dendrogram
Z=linkage(df1[["Weight","Height"]],method="ward",metric="euclidean")
plt.figure(figsize=(10, 5))
dendrogram(Z)
plt.title("Hierarchical Clustering Dendrogram")
plt.xlabel("Data Points")
plt.ylabel("Distance")
plt.show()

from sklearn.cluster import AgglomerativeClustering
agg=AgglomerativeClustering(linkage="ward",n_clusters=3)
labels=agg.fit_predict(df1[["Weight","Height"]])

df1["agglabel"]=labels

#plotting the data and clusters
plt.scatter(df1.iloc[0:,0][df1["agglabel"]==0],df1.iloc[0:,1][df1["agglabel"]==0],color="green")
plt.scatter(df1.iloc[0:,0][df1["agglabel"]==1],df1.iloc[0:,1][df1["agglabel"]==1],color="blue")
plt.scatter(df1.iloc[0:,0][df1["agglabel"]==2],df1.iloc[0:,1][df1["agglabel"]==2])
plt.xlabel("Weight")
plt.ylabel("Height")
plt.title("clusterig using K Means Clustering")
plt.show()

"""#Clustering using the Hierarchical Clustering on dataset2"""

X=df2[["Annual Income (k$)","Spending Score (1-100)"]]

#drawing the dendrogram
from scipy.cluster.hierarchy import linkage,dendrogram
Z=linkage(X,method="ward",metric="euclidean")
plt.figure(figsize=(10, 5))
dendrogram(Z)
plt.title("Hierarchical Clustering Dendrogram")
plt.xlabel("Data Points")
plt.ylabel("Distance")
plt.show()

from sklearn.cluster import AgglomerativeClustering
agg=AgglomerativeClustering(linkage="ward",n_clusters=2)
labels=agg.fit_predict(X)

X["agglabel"]=labels

X

#plotting the data and clusters
plt.scatter(X.iloc[0:,0][X["agglabel"]==0],X.iloc[0:,1][X["agglabel"]==0],color="green")
plt.scatter(X.iloc[0:,0][X["agglabel"]==1],X.iloc[0:,1][X["agglabel"]==1],color="blue")
plt.scatter(X.iloc[0:,0][X["agglabel"]==2],X.iloc[0:,1][X["agglabel"]==2])
plt.xlabel("Weight")
plt.ylabel("Height")
plt.title("clusterig using K Means Clustering")
plt.show()

"""#Clustering using the DBSCAN Clustering on dataset1"""

X=df1[["Weight","Height"]]

from sklearn.cluster import DBSCAN
db=DBSCAN(eps=1,min_samples=8)
labels=db.fit_predict(X)

X["label"]=labels

X["label"].value_counts()

#plotting the data and clusters
plt.scatter(X.iloc[0:,0][X["label"]==0],X.iloc[0:,1][X["label"]==0],color="green")
plt.scatter(X.iloc[0:,0][X["label"]==1],X.iloc[0:,1][X["label"]==1],color="blue")
plt.scatter(X.iloc[0:,0][X["label"]==2],X.iloc[0:,1][X["label"]==2],color="red")
plt.scatter(X.iloc[0:,0][X["label"]==-1],X.iloc[0:,1][X["label"]==-1],color="black")
plt.xlabel("Weight")
plt.ylabel("Height")
plt.title("clusterig using K Means Clustering")
plt.show()

