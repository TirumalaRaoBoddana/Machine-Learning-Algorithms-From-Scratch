# -*- coding: utf-8 -*-
"""kmeans-clustering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BfSwUj0UWMwqZxmHaYi4DXDWfITxRLV0
"""

import numpy as np
import pandas as pd

df = pd.read_csv('/content/student_clustering.csv')
print("The shape of data is",df.shape)
df.head()

import matplotlib.pyplot as plt
plt.scatter(df['cgpa'],df['iq'])

from sklearn.cluster import KMeans

wcss = []
for i in range(1,11):
    km = KMeans(n_clusters=i)
    km.fit_predict(df)
    wcss.append(km.inertia_)

wcss

plt.plot(range(1,11),wcss)

X = df.iloc[:,:].values
km = KMeans(n_clusters=4)
y_means = km.fit_predict(X)

y_means

X[y_means == 3,0]

plt.scatter(X[y_means == 0,0],X[y_means == 0,1],color='blue')
plt.scatter(X[y_means == 1,0],X[y_means == 1,1],color='red')
plt.scatter(X[y_means == 2,0],X[y_means == 2,1],color='green')
plt.scatter(X[y_means == 3,0],X[y_means == 3,1],color='yellow')

"""# K-Means on 3-D Data"""

from sklearn.datasets import make_blobs

centroids = [(-5,-5,5),(5,5,-5),(3.5,-2.5,4),(-2.5,2.5,-4)]
cluster_std = [1,1,1,1]

X,y = make_blobs(n_samples=200,cluster_std=cluster_std,centers=centroids,n_features=3,random_state=1)

X

import plotly.express as px
fig = px.scatter_3d(x=X[:,0], y=X[:,1], z=X[:,2])
fig.show()

wcss = []
for i in range(1,21):
    km = KMeans(n_clusters=i)
    km.fit_predict(X)
    wcss.append(km.inertia_)

plt.plot(range(1,21),wcss)

km = KMeans(n_clusters=4)
y_pred = km.fit_predict(X)

df = pd.DataFrame()

df['col1'] = X[:,0]
df['col2'] = X[:,1]
df['col3'] = X[:,2]
df['label'] = y_pred

fig = px.scatter_3d(df,x='col1', y='col2', z='col3',color='label')
fig.show()

"""**Implment K means clustering on real world dataset**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

#importign the dataset
data=pd.read_csv("/content/wine-clustering.csv")

data.shape

#describe
data.describe()

#info
data.info()

#checking the null values
data.isnull().sum()

#data types of the columns
data.dtypes

data[["Magnesium","Proline"]].astype("float64")

#standardizing the data
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
scaler = StandardScaler()
X_scaled = scaler.fit_transform(data)

X_scaled.shape

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

wcss = []
best_score = -1
best_k = 2
for k in range(2, 15):
    kmeans = KMeans(n_clusters=k, max_iter=300, n_init=10, random_state=42)
    labels = kmeans.fit_predict(X_scaled)

    wcss.append(kmeans.inertia_)

    s = silhouette_score(X_scaled, labels)

    if s > best_score:
        best_score = s
        best_k = k

print("Best Silhouette Score:", best_score)
print("Best K:", best_k)

import matplotlib.pyplot as plt

plt.plot(range(2,15), wcss, marker='o')
plt.xlabel("Number of clusters K")
plt.ylabel("WCSS (inertia)")
plt.title("Elbow Method")
plt.show()

km=KMeans(n_clusters=3,max_iter=300,n_init=10)
labels=km.fit_predict(X_scaled)

labels

from sklearn.metrics import silhouette_score
score = silhouette_score(X_scaled, km.labels_)
print(score)

"""#**Building the custom K Means clustering algorithm**"""

class KMeansClustering:

  def __init__(self, clusters, max_iter=100):
      self.clusters = clusters
      self.max_iter = max_iter
      self.cluster_labels = {}
      self.centroids = {}

  def find_distance(self, datapoint, centroid):
      return np.sum((datapoint - centroid)**2)  # squared distance

  def assign_centroid(self, X):
      cluster_labels = {i: [] for i in range(self.clusters)}
      for idx, point in enumerate(X):
          distances = [self.find_distance(point, self.centroids[c]) for c in self.centroids]
          cluster = np.argmin(distances)
          cluster_labels[cluster].append(idx)
      self.cluster_labels = cluster_labels

  def update_centroids(self, X):
      for c in self.cluster_labels:
          if len(self.cluster_labels[c]) > 0:
              self.centroids[c] = np.mean(X[self.cluster_labels[c]], axis=0)

  def fit_predict(self, X):
      # Convert DataFrame → NumPy
      X = np.asarray(X)

      # initialize centroids randomly
      random_indices = np.random.choice(len(X), self.clusters, replace=False)
      self.centroids = {i: X[idx] for i, idx in enumerate(random_indices)}

      for _ in range(self.max_iter):
          self.assign_centroid(X)
          old_centroids = self.centroids.copy()
          self.update_centroids(X)

          # check convergence
          converged = True
          for c in self.centroids:
              if not np.allclose(old_centroids[c], self.centroids[c]):
                  converged = False
                  break
          if converged:
              break

      # build label array
      labels = np.zeros(len(X), dtype=int)
      for c, pts in self.cluster_labels.items():
          for p in pts:
              labels[p] = c
      return labels

  def inertia(self, X):
      X = np.asarray(X)  # convert DataFrame → NumPy
      total_wcss = 0
      for c, points in self.cluster_labels.items():
          centroid = self.centroids[c]
          for idx in points:
              total_wcss += np.sum((X[idx] - centroid)**2)
      return total_wcss

"""#Elbow method to find the best number of clusters"""

wcss=[]
for i in range(2,16,1):
  km=KMeansClustering(clusters=i)
  labels=km.fit_predict(data)
  wcss.append(km.inertia(data))

import matplotlib.pyplot as plt
plt.plot(range(2,16,1),wcss)
plt.xlabel("no.of clusters")
plt.ylabel("wcss")
plt.show()

"""#using silhouette_score to find the best k"""

max_score=float("-inf")
k=-1
for i in range(2,16,1):
  km=KMeansClustering(clusters=i,max_iter=300)
  labels=km.fit_predict(data)
  score=silhouette_score(data,labels)
  if(score>max_score):
    max_score=score
    k=i

print("maximum silhouwtte score",max_score)
print("no.of clusters: ",k)

km=KMeansClustering(clusters=k,max_iter=300)
labels=km.fit_predict(data)

score=silhouette_score(data,labels)
score

